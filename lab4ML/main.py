import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import Perceptron
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.io import arff

# -----------------------------
# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ CSV
# -----------------------------
file_path = "C:\\Users\\dima2\\PycharmProjects\\lab4ML\\messidor_features.arff"

# –ó–∞–≥—Ä—É–∂–∞–µ–º arff —á–µ—Ä–µ–∑ scipy
data, meta = arff.loadarff(file_path)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
df = pd.DataFrame(data)

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±–∏–Ω–∞—Ä–Ω—ã–π –∫–ª–∞—Å—Å –∏–∑ bytes –≤ int
df['Class'] = df['Class'].apply(lambda x: int(x.decode('utf-8')) if isinstance(x, bytes) else int(x))

# –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
X = df.drop(columns=['Class']).values
y = df['Class'].values

print("–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –†–∞–∑–º–µ—Ä:", X.shape)

# -----------------------------------
# 2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test
# -----------------------------------
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

print(f"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}")

# ------------------------------
# 3. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
# ------------------------------
scaler = StandardScaler()
scalerMinMax = MinMaxScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

X_train_minMax = scalerMinMax.fit_transform(X_train)
X_val_minMax = scalerMinMax.transform(X_val)
X_test_minMax = scalerMinMax.transform(X_test)

# ------------------------------
# 4. –û–±—É—á–µ–Ω–∏–µ Perceptron
# ------------------------------
perceptron = Perceptron(max_iter=1000, penalty='l1', eta0=0.01, random_state=42)
perceptron.fit(X_train_scaled, y_train)
y_pred_perceptron = perceptron.predict(X_test_scaled)
acc_perceptron = accuracy_score(y_test, y_pred_perceptron)
print("Perceptron Accuracy on test set:", acc_perceptron)

# ------------------------------
# 5. –û–±—É—á–µ–Ω–∏–µ MLPClassifier
# ------------------------------

activation = ['relu', 'tanh', 'logistic']
optimizers = ['sgd', 'adam', 'lbfgs']
for activator in activation:
    for optimizer in optimizers:
        mlp = MLPClassifier(
            hidden_layer_sizes=(100,50),
            activation=activator,
            solver=optimizer,
            alpha=0.005,
            learning_rate_init=0.01,
            max_iter=5000,
            random_state=42
        )
        mlp.fit(X_train_scaled, y_train)
        y_pred_mlp = mlp.predict(X_test_scaled)
        acc_mlp = accuracy_score(y_test, y_pred_mlp)
        print(f"MLPClassifier Accuracy on test set:{acc_mlp} optimizer {optimizer}, activator {activator}")

        mlp.fit(X_train_minMax, y_train)
        y_pred_mlp = mlp.predict(X_test_minMax)
        acc_mlp = accuracy_score(y_test, y_pred_mlp)
        print(f"MLPClassifier Accuracy on test set (MinMax):{acc_mlp} optimizer {optimizer}, activator {activator}")

# ------------------------------
# 6. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã MLP
# ------------------------------
learning_rates = [0.0001, 0.001, 0.01]
alphas = [0.0001, 0.001, 0.005]
results = []

for solver in optimizers:
    for lr in learning_rates:
        for alpha in alphas:
            mlp_exp = MLPClassifier(
                hidden_layer_sizes=(100,50),
                activation='relu',
                solver=solver,
                alpha=alpha,
                learning_rate_init=lr,
                max_iter=2000,
                random_state=42
            )
            mlp_exp.fit(X_train_scaled, y_train)
            val_acc = accuracy_score(y_val, mlp_exp.predict(X_val_scaled))
            results.append((solver, lr, alpha, val_acc))

results_df = pd.DataFrame(results, columns=['solver', 'learning_rate', 'alpha', 'val_accuracy'])
print("\n–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤:")
print(results_df)

# ------------------------------
# 7. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
# ------------------------------
for solver in optimizers:
    subset = results_df[results_df['solver'] == solver]
    pivot_table = subset.pivot(index='alpha', columns='learning_rate', values='val_accuracy')
    plt.figure(figsize=(8,6))
    sns.heatmap(pivot_table, annot=True, fmt=".3f", cmap="viridis")
    plt.title(f"Validation Accuracy ({solver.upper()})")
    plt.ylabel("Alpha (regularization)")
    plt.xlabel("Learning Rate")
    plt.show()

# ------------------------------
# 8. –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ MLP
# ------------------------------
from sklearn.model_selection import GridSearchCV

param_grid = {
    'hidden_layer_sizes': [(50,), (100,), (100,50), (150,75)],
    'activation': ['relu', 'tanh', 'logistic'],
    'solver': ['adam', 'lbfgs', 'sgd'],
    'alpha': [0.0001, 0.001, 0.005],
    'learning_rate_init': [0.0001, 0.001, 0.01],
}

mlp = MLPClassifier(max_iter=10000, random_state=42)

grid_search = GridSearchCV(
    estimator=mlp,
    param_grid=param_grid,
    scoring='accuracy',
    cv=3,              # –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ 3 —Ñ–æ–ª–¥–∞
    n_jobs=-1,         # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ —è–¥—Ä–∞ CPU
    verbose=2
)

print("\nüîç –ó–∞–ø—É—Å–∫ –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç)...")
grid_search.fit(X_train_scaled, y_train)

# ------------------------------
# 9. –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
# ------------------------------
print("\n–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã MLPClassifier:")
print(grid_search.best_params_)

print("\n–õ—É—á—à–∞—è —Å—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å (CV):", grid_search.best_score_)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
best_mlp = grid_search.best_estimator_
test_acc = accuracy_score(y_test, best_mlp.predict(X_test_scaled))
print("\n–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:", test_acc)
